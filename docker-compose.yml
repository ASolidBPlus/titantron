services:
  titantron:
    build: .
    ports:
      - "8765:8765"
    volumes:
      - titantron-config:/config
      # Mount video libraries for audio analysis (bell/music detection):
      # - /path/to/media:/media:ro
      # Then in Admin > Setup, set:
      #   Jellyfin Path: /data/videos  (Jellyfin's internal path)
      #   Local Path:    /media         (container mount point)
    env_file:
      - .env
    environment:
      - TITANTRON_DB_PATH=/config/titantron.db
      - TITANTRON_FRONTEND_DIR=/app/frontend-build
    restart: unless-stopped

  # ── ML-powered music detection (optional) ──
  # Uncomment to enable, then set ML Service URL in Admin > Settings
  # to http://titantron-ml:8769
  # First start installs dependencies (~2 min), cached in volume for subsequent starts.
  # Auto-detects CUDA — add deploy.resources for GPU support.
  # titantron-ml:
  #   image: ghcr.io/asolidbplus/titantron-ml:latest
  #   volumes:
  #     - ml-cache:/cache  # persists installed deps + downloaded model
  #   restart: unless-stopped
  #   # Uncomment for GPU support (requires nvidia-container-toolkit):
  #   # deploy:
  #   #   resources:
  #   #     reservations:
  #   #       devices:
  #   #         - capabilities: [gpu]

volumes:
  titantron-config:
  # ml-cache:  # uncomment with titantron-ml
