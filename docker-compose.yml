services:
  titantron:
    build: .
    ports:
      - "8765:8765"
    volumes:
      - titantron-config:/config
      # Mount video libraries for audio analysis (bell/music detection):
      # - /path/to/media:/media:ro
      # Then in Admin > Setup, set:
      #   Jellyfin Path: /data/videos  (Jellyfin's internal path)
      #   Local Path:    /media         (container mount point)
    env_file:
      - .env
    environment:
      - TITANTRON_DB_PATH=/config/titantron.db
      - TITANTRON_FRONTEND_DIR=/app/frontend-build
    restart: unless-stopped

  # ── ML-powered music detection (optional) ──
  # Uncomment ONE of the variants below, then set ML Service URL
  # in Admin > Settings to http://titantron-ml:8769

  # CPU variant (~1.5GB image, ~2-4 min per 2hr video)
  # titantron-ml:
  #   image: ghcr.io/asolidbplus/titantron-ml:latest
  #   volumes:
  #     - ml-models:/root/.cache
  #   restart: unless-stopped

  # CUDA variant (~6GB image, seconds per video — requires NVIDIA GPU)
  # titantron-ml:
  #   image: ghcr.io/asolidbplus/titantron-ml:cuda-latest
  #   volumes:
  #     - ml-models:/root/.cache
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - capabilities: [gpu]

volumes:
  titantron-config:
  # ml-models:  # uncomment with titantron-ml
